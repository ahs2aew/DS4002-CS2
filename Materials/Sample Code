Here is some sample code for performing some potentially important processes, should you choose to explore the sentiment analysis route with this project. 

Some necessary packages:
import textblob 
from textblob import TextBlob



If you wanted to add a column that gives a "political bias label" for each publication (could use the media bias chart to come up with these labels): 
# adding a column for article bias
bias_labels = {'Atlantic': 'lean left', 'Breitbart': 'right', 'Business Insider': 'lean left', 'Buzzfeed News': 'left', 'CNN': 'left', 'Fox News': 'right',
                'Guardian': 'lean left', 'National Review': 'right', 'New York Post': 'lean right', 'New York Times': 'lean left',
                'NPR': 'left', 'Reuters': 'center', 'Talking Points Memo': 'left', 'Washington Post': 'lean left', 'Vox': 'left'}
articles['bias'] = articles['publication'].apply(lambda x: bias_labels[x]) # go through the articles publication column, for each x apply the bias label 



Example function for tokenization (cleaning up the text): 
# this cleaning function is from https://www.dataquest.io/blog/tutorial-text-analysis-python-test-hypothesis/
def clean_text(article):
    clean1 = re.sub(r'['+string.punctuation + '’—”'+']', "", article.lower())
    return re.sub(r'\W+', ' ', clean1)
articles['clean title'] = articles['title'].map(lambda x: clean_text(x)) # this part applies the clean_text function to all article titles 


Example function for performing polarity analysis: 
sentiment=[] # this will be the polarity scores that will make up a new column called "polarity score" 
for i in dataframe['clean content']: # looking through the column that contains the tokenized (aka clean) article content 
    txt= TextBlob(i)
    a= txt.sentiment.polarity
    sentiment.append(a)
dataframe['polarity score'] = sentiment # adding a new "polarity score" column



